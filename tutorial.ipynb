{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e16f628-7ad4-4bd5-b81d-1bc0dbabb867",
   "metadata": {},
   "source": [
    "# GraphSL example notebook\n",
    "\n",
    "\n",
    "## load libraries\n",
    "\n",
    "We load all available methods from GraphSL i.e. `GCNSI`, `IVGD`, and `SLVAE` from the GNN based methods and `LPSI`, `NetSleuth` and `OJC` from the prescribed methods.\n",
    "Furthermore we load some utilities from GraphSL, to deal with the dataset (e.g. download it and split it into a training and test dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71c99a9-abe2-4de1-aeb9-117f99a9c235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load methods\n",
    "from GraphSL.GNN.SLVAE.main import SLVAE\n",
    "from GraphSL.GNN.IVGD.main import IVGD\n",
    "from GraphSL.GNN.GCNSI.main import GCNSI\n",
    "from GraphSL.Prescribed import LPSI, NetSleuth, OJC\n",
    "# load utils\n",
    "from GraphSL.utils import load_dataset, diffusion_generation, split_dataset, download_dataset, visualize_source_prediction\n",
    "# other imports\n",
    "import os\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a544d9-187c-43ba-896d-48e32218046f",
   "metadata": {},
   "source": [
    "## dataset preparation\n",
    "\n",
    "### Download dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a10574d-ab5c-43af-949f-a65c19d97b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = widgets.Dropdown(\n",
    "    options=['karate', 'dolphins', 'jazz', 'netscience', 'cora_ml', 'power_grid'],\n",
    "    value='karate',\n",
    "    description='Dataset:',\n",
    "    disabled=False,\n",
    ")\n",
    "data_name = w.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2783f4-9ff7-4e93-912d-33b6522ae6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory is: /nfs/users/junxiang/personal/GraphSL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "curr_dir = os.getcwd()\n",
    "print(f\"Current working directory is: {curr_dir}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b378438-6b92-41ec-b6e0-9901273522e1",
   "metadata": {},
   "source": [
    "all datasets will be downloaded to the local `data` folder in the `curr_dir` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44011101-0b74-4b9d-968e-50e330bc9e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded cora_ml\n",
      "Downloaded dolphins\n",
      "Downloaded jazz\n",
      "Downloaded karate\n",
      "Downloaded netscience\n",
      "Downloaded power_grid\n"
     ]
    }
   ],
   "source": [
    "download_dataset(curr_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6f9a8-9070-400b-892e-0a0a1067630f",
   "metadata": {},
   "source": [
    "### Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba7598c-6845-4c28-8165-aee34c89f99c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24615d6c82a47f98e001da78a1b530b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Dataset:', options=('karate', 'dolphins', 'jazz', 'netscience', 'cora_ml', 'power_grid')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1978fa8d-fcc3-4454-8129-6a52f41d5101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adj_mat': <34x34 sparse matrix of type '<class 'numpy.float32'>'\n",
      "\twith 156 stored elements in Compressed Sparse Row format>}\n"
     ]
    }
   ],
   "source": [
    "graph = load_dataset(data_name, data_dir=curr_dir)\n",
    "# print graph \n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b535e8d-e740-4c08-90e5-e555b60ea17b",
   "metadata": {},
   "source": [
    "### pre-processing dataset\n",
    "\n",
    "generate diffusion using Independent Cascade(IC) model, the infection probability is `0.3`, the number of simulations is `100`, the probability of sources(seeds) is `0.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeff29ee-c7e5-491b-8440-5095ce728cea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adj_mat': <34x34 sparse matrix of type '<class 'numpy.float32'>'\n",
       " \twith 156 stored elements in Compressed Sparse Row format>,\n",
       " 'diff_mat': tensor([[[1., 1.],\n",
       "          [0., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          [1., 1.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [0., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [0., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.]],\n",
       " \n",
       "         [[1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          ...,\n",
       "          [1., 1.],\n",
       "          [1., 1.],\n",
       "          [1., 1.]]])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = diffusion_generation(graph=graph, infect_prob=0.3, diff_type='IC', sim_num=100, seed_ratio=0.2)\n",
    "display(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725c7ccc-4c3f-4c60-a961-b7993cb8b4fc",
   "metadata": {},
   "source": [
    "#### split the dataset into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67df8d67-5263-4347-9c52-cf41e809d043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dataset: <torch.utils.data.dataset.Subset object at 0x7f5e0e1dd910>\n",
      "Test dataset: <torch.utils.data.dataset.Subset object at 0x7f5e0e1de960>\n"
     ]
    }
   ],
   "source": [
    "adj, train_dataset, test_dataset = split_dataset(dataset)\n",
    "print(f\"Training dataset: {train_dataset}\")\n",
    "print(f\"Test dataset: {test_dataset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bacb382-8427-4cf8-a473-b545785e9810",
   "metadata": {},
   "source": [
    "## Execute methods\n",
    "\n",
    "executing the methods is split into two parts for every method. A **training** and a **test** step. In the training step, the `train` function of the selected method is called to train the model on the training set, and hyperparameters (e.g. threshold) are optimized based on F1-score. In the test step, the trained model is evaluated on the test set to verify its performance, which is returned by the **Metric** object. The Metric object consists of five performance metrics: accuracy (acc), precision (pr), recall (re), F1-score (fs) and the area under the ROC curve (auc). The higher these performance metrics are, the better a model performs. They are defined as follows:\n",
    "\n",
    "**Accuracy (ACC)**: Accuracy is the ratio of correctly predicted instances to the total number of instances. It is a measure of how often the classifier is correct overall. ACC = 1 means the model is perfect, while ACC = 0 means the model is completely wrong.\n",
    "\n",
    "Formula: Accuracy = (True Positives + True Negatives)/ Total Number of Instances, where\n",
    "\n",
    "True Positives (TP): Instances where the model correctly predicted the positive class.\n",
    "\n",
    "True Negatives (TN): Instances where the model correctly predicted the negative class.\n",
    "\n",
    "Accuracy is useful when the classes are balanced, but it can be misleading if there is a class imbalance.\n",
    "\n",
    "**Precision (PR)**: Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. It indicates how many of the predicted positive instances were actually positive.\n",
    "\n",
    "Formula: Precision = True Positives/ (True Positives + False Positives), where\n",
    "\n",
    "False Positives (FP): Instances where the model incorrectly predicted the positive class.\n",
    "\n",
    "Precision is important in scenarios where the cost of false positives is high.\n",
    "\n",
    "**Recall (RE)**: Recall, also known as sensitivity or true positive rate, is the ratio of correctly predicted positive observations to all actual positive observations. It measures the model's ability to detect positive instances.\n",
    "\n",
    "Formula: Recall = True Positives/ (True Positives + False Negatives), where\n",
    "\n",
    "False Negatives (FN): Instances where the model incorrectly predicted the negative class.\n",
    "\n",
    "Recall is important in situations where the cost of false negatives is high.\n",
    "\n",
    "**F1-Score (FS)**: The F1-score is the harmonic mean of precision and recall, providing a balance between the two metrics. It is useful when you need a single metric to evaluate the performance of a model with imbalanced classes.\n",
    "\n",
    "Formula: F1-Score = 2 × Precision × Recall / (Precision + Recall)\n",
    "\n",
    "The F1-score takes both false positives and false negatives into account.\n",
    "\n",
    "It is best used when the class distribution is uneven or when both precision and recall are important.\n",
    "\n",
    "**Area Under the ROC Curve (AUC)**: The AUC represents the area under the Receiver Operating Characteristic (ROC) curve, which plots the true positive rate against the false positive rate at various threshold settings.\n",
    "\n",
    "The ROC curve illustrates the trade-off between sensitivity (recall) and specificity (1 - false positive rate).\n",
    "\n",
    "The AUC is a single scalar value that summarizes the overall performance of the model across all classification thresholds.\n",
    "\n",
    "AUC values range from 0 to 1, where 1 indicates a perfect model, 0.5 suggests no discriminative power (equivalent to random guessing), and 0 means a completely wrong model.\n",
    "\n",
    "A higher AUC indicates better model performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae6f8da-f444-45a6-b020-bd1b14055039",
   "metadata": {},
   "source": [
    "### LPSI\n",
    "\n",
    "#### training\n",
    "train LPSI using the training set, and return the hyperparameter `alpha`, the optimal threshold, the area under the ROC curve, F1-Score, and source predictions,\n",
    "source predictions can be utilized to adjust the parameter `thres_list` in `lpsi.train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0554abcd-9c8a-40cd-b5e7-ce4e8094027b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lpsi.train:\n",
      "========================\n",
      "alpha = 0.001, train_auc = 0.693\n",
      "alpha = 0.01, train_auc = 0.693\n",
      "alpha = 0.1, train_auc = 0.589\n",
      "thres = 0.454, train_f1 = 0.308\n",
      "thres = 0.508, train_f1 = 0.316\n",
      "thres = 0.563, train_f1 = 0.316\n",
      "thres = 0.618, train_f1 = 0.333\n",
      "thres = 0.672, train_f1 = 0.333\n",
      "thres = 0.727, train_f1 = 0.364\n",
      "thres = 0.781, train_f1 = 0.364\n",
      "thres = 0.836, train_f1 = 0.429\n",
      "thres = 0.890, train_f1 = 0.429\n",
      "thres = 0.945, train_f1 = 0.526\n",
      "========================\n",
      "\n",
      "training done\n",
      "\n",
      "train auc: 0.693, train f1: 0.526\n"
     ]
    }
   ],
   "source": [
    "lpsi = LPSI()\n",
    "\n",
    "print(\"lpsi.train:\")\n",
    "print(\"========================\")\n",
    "alpha, thres, auc, f1, pred = lpsi.train(adj, train_dataset)\n",
    "print(\"========================\\n\")\n",
    "print(\"training done\\n\")\n",
    "print(f\"train auc: {auc:.3f}, train f1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8beba-101b-43eb-a862-a96322935851",
   "metadata": {},
   "source": [
    "#### testing\n",
    "\n",
    "test LPSI using the test set, and return the Metric object (accuracy, precision, recall, F1-Score and area under the ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "166a54df-76af-4a3e-860c-eee197a0b958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.749, test pr: 0.402, test re: 0.871, test f1: 0.550, test auc: 0.695\n"
     ]
    }
   ],
   "source": [
    "metric = lpsi.test(adj, test_dataset, alpha, thres)\n",
    "print(f\"test acc: {metric.acc:.3f}, test pr: {metric.pr:.3f}, test re: {metric.re:.3f}, test f1: {metric.f1:.3f}, test auc: {metric.auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93c0540-2512-48e7-ac25-1288e62094b9",
   "metadata": {},
   "source": [
    "Based on five performance metrics, the LPSI does not perform well.\n",
    "\n",
    "### NetSleuth\n",
    "\n",
    "#### training\n",
    "\n",
    "train NetSleuth using the training set, and return the hyperparameter 'k', the area under the ROC curve, and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac9d7668-7e2e-4080-8cc7-0fc7ccc13791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netSleuth.train:\n",
      "========================\n",
      "k = 2, train_auc = 0.643\n",
      "k = 5, train_auc = 0.854\n",
      "k = 10, train_auc = 0.765\n",
      "========================\n",
      "\n",
      "training done\n",
      "\n",
      "train auc: 0.854, train f1: 0.797\n"
     ]
    }
   ],
   "source": [
    "netSleuth = NetSleuth()\n",
    "\n",
    "print(\"netSleuth.train:\")\n",
    "print(\"========================\")\n",
    "k, auc, f1 = netSleuth.train(adj, train_dataset)\n",
    "print(\"========================\\n\")\n",
    "print(\"training done\\n\")\n",
    "print(f\"train auc: {auc:.3f}, train f1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e938e6-5e4f-4d6b-a5fb-24033690374b",
   "metadata": {},
   "source": [
    "#### testing\n",
    "\n",
    "test NetSleuth using the test set, and return the Metric object (accuracy, precision, recall, F1-Score and area under the ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "483ea6a8-7a7d-4176-8bdb-784927ce8823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.937, test pr: 0.885, test re: 0.738, test f1: 0.805, test auc: 0.858\n"
     ]
    }
   ],
   "source": [
    "metric = netSleuth.test(adj, test_dataset, k)\n",
    "print(f\"test acc: {metric.acc:.3f}, test pr: {metric.pr:.3f}, test re: {metric.re:.3f}, test f1: {metric.f1:.3f}, test auc: {metric.auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd70fd-091b-4208-b9f6-39dfc1640ff8",
   "metadata": {},
   "source": [
    "The performance of NetSleuth is better than the LPSI.\n",
    "\n",
    "### OJC\n",
    "\n",
    "#### training\n",
    "\n",
    "train OJC using the training set, and return the hyperparameter 'Y', area under the ROC curve, and F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b13d2e73-b082-499a-9c03-9bfacabedac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ojc.train:\n",
      "========================\n",
      "Y = 2, train_auc = 0.619\n",
      "Y = 5, train_auc = 0.619\n",
      "Y = 10, train_auc = 0.619\n",
      "========================\n",
      "\n",
      "training done\n",
      "\n",
      "train auc: 0.619, train f1: 0.365\n"
     ]
    }
   ],
   "source": [
    "ojc = OJC()\n",
    "\n",
    "print(\"ojc.train:\")\n",
    "print(\"========================\")\n",
    "Y, auc, f1 = ojc.train(adj, train_dataset)\n",
    "print(\"========================\\n\")\n",
    "print(\"training done\\n\")\n",
    "print(f\"train auc: {auc:.3f}, train f1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f10ab0-07cd-42b9-b2fa-24a239d45708",
   "metadata": {},
   "source": [
    "#### testing \n",
    "\n",
    "test OJC using the test set, and return the Metric object (accuracy, precision, recall, F1-Score and area under the ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ebaf8e3-13e1-4d9c-8537-fd4c87e7efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.635, test pr: 0.254, test re: 0.550, test f1: 0.347, test auc: 0.602\n"
     ]
    }
   ],
   "source": [
    "metric = ojc.test(adj, test_dataset, Y)\n",
    "print(f\"test acc: {metric.acc:.3f}, test pr: {metric.pr:.3f}, test re: {metric.re:.3f}, test f1: {metric.f1:.3f}, test auc: {metric.auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a70ebf-4780-41e1-b683-de5bbac04ee0",
   "metadata": {},
   "source": [
    "### GCNSI\n",
    "\n",
    "#### training\n",
    "train GCNSI using the training set, and return the GCNSI model, the optimal threshold, the area under the ROC curve, F1-Score, and source predictions \n",
    "source predictions can be utilized to adjust the parameter `thres_list` in `gcnsi.train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efddefa1-fed7-44f6-b84f-bd35dd31cb58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcnsi.train:\n",
      "========================\n",
      "train GCNSI:\n",
      "Epoch [0/100], loss = 7.445\n",
      "Epoch [10/100], loss = 0.832\n",
      "Epoch [20/100], loss = 0.684\n",
      "Epoch [30/100], loss = 0.595\n",
      "Epoch [40/100], loss = 0.535\n",
      "Epoch [50/100], loss = 0.532\n",
      "Epoch [60/100], loss = 0.453\n",
      "Epoch [70/100], loss = 0.565\n",
      "Epoch [80/100], loss = 0.415\n",
      "Epoch [90/100], loss = 0.401\n",
      "train_auc = 0.984\n",
      "thres = 0.148, train_f1 = 0.308\n",
      "thres = 0.233, train_f1 = 0.429\n",
      "thres = 0.318, train_f1 = 0.545\n",
      "thres = 0.403, train_f1 = 0.545\n",
      "thres = 0.489, train_f1 = 0.545\n",
      "thres = 0.574, train_f1 = 0.750\n",
      "thres = 0.659, train_f1 = 0.750\n",
      "thres = 0.744, train_f1 = 0.750\n",
      "thres = 0.830, train_f1 = 0.923\n",
      "thres = 0.915, train_f1 = 0.797\n",
      "========================\n",
      "\n",
      "training done\n",
      "\n",
      "train auc: 0.984, train f1: 0.923\n"
     ]
    }
   ],
   "source": [
    "gcnsi = GCNSI()\n",
    "\n",
    "print(\"gcnsi.train:\")\n",
    "print(\"========================\")\n",
    "gcnsi_model, thres, auc, f1, pred = gcnsi.train(adj, train_dataset)\n",
    "print(\"========================\\n\")\n",
    "print(\"training done\\n\")\n",
    "print(f\"train auc: {auc:.3f}, train f1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b259c",
   "metadata": {},
   "source": [
    "### visualization\n",
    "visualize the predicted sources and the labeled sources and save the figure to the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce788527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /nfs/users/junxiang/personal/GraphSL/GCNSI_source_prediction.png\n"
     ]
    }
   ],
   "source": [
    "pred = (pred >= thres)\n",
    "visualize_source_prediction(adj,pred[:,0],train_dataset[0][:,0].numpy(),save_dir=curr_dir,save_name=\"GCNSI_source_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60d1eea-7203-4c8a-926e-a63240c65791",
   "metadata": {},
   "source": [
    "#### testing\n",
    "\n",
    "test GCNSI using the test set, and return the Metric object (accuracy, precision, recall, F1-Score, and area under the ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46abe0dc-504f-4ebf-8295-622da593591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.971, test pr: 0.857, test re: 1.000, test f1: 0.923, test auc: 0.986\n"
     ]
    }
   ],
   "source": [
    "metric = gcnsi.test(adj, test_dataset, gcnsi_model, thres)\n",
    "print(f\"test acc: {metric.acc:.3f}, test pr: {metric.pr:.3f}, test re: {metric.re:.3f}, test f1: {metric.f1:.3f}, test auc: {metric.auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcbc884-ecc0-44c6-b398-bd256ef21738",
   "metadata": {},
   "source": [
    "\n",
    "### IVGD\n",
    "\n",
    "#### training\n",
    "\n",
    "First train IVGD diffusion model using the training set and return the diffusion model\n",
    "\n",
    "Then train IVGD using the training set, and return the IVGD model, the optimal threshold, the area under the ROC curve, the F1-score, and source predictions. Source predictions can be utilized to adjust the parameter `thres_list` in `ivgd.train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5a5c438-6994-4347-879e-728974716ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivgd.train_diffusion:\n",
      "========================\n",
      "train IVGD diffusion model:\n",
      "Epoch [0/50], Loss: 0.005\n",
      "Epoch [10/50], Loss: 0.001\n",
      "Epoch [20/50], Loss: 0.001\n",
      "Epoch [30/50], Loss: 0.001\n",
      "Epoch [40/50], Loss: 0.001\n",
      "========================\n",
      "\n",
      "ivgd.train:\n",
      "========================\n",
      "train IVGD:\n",
      "Epoch [0/200], loss = 1.004\n",
      "Epoch [10/200], loss = 0.571\n",
      "Epoch [20/200], loss = 0.330\n",
      "Epoch [30/200], loss = 0.292\n",
      "Epoch [40/200], loss = 0.266\n",
      "Epoch [50/200], loss = 0.255\n",
      "Epoch [60/200], loss = 0.257\n",
      "Epoch [70/200], loss = 0.249\n",
      "Epoch [80/200], loss = 0.247\n",
      "Epoch [90/200], loss = 0.237\n",
      "Epoch [100/200], loss = 0.247\n",
      "Epoch [110/200], loss = 0.230\n",
      "Epoch [120/200], loss = 0.228\n",
      "Epoch [130/200], loss = 0.307\n",
      "Epoch [140/200], loss = 0.284\n",
      "Epoch [150/200], loss = 0.254\n",
      "Epoch [160/200], loss = 0.244\n",
      "Epoch [170/200], loss = 0.248\n",
      "Epoch [180/200], loss = 0.242\n",
      "Epoch [190/200], loss = 0.239\n",
      "thres = 0.091, train_f1 = 0.800\n",
      "thres = 0.182, train_f1 = 0.800\n",
      "thres = 0.273, train_f1 = 0.800\n",
      "thres = 0.364, train_f1 = 0.800\n",
      "thres = 0.455, train_f1 = 0.800\n",
      "thres = 0.545, train_f1 = 0.800\n",
      "thres = 0.636, train_f1 = 0.800\n",
      "thres = 0.727, train_f1 = 0.867\n",
      "thres = 0.818, train_f1 = 0.867\n",
      "thres = 0.909, train_f1 = 0.867\n",
      "========================\n",
      "\n",
      "training done\n",
      "\n",
      "train auc: 0.984, train f1: 0.867\n"
     ]
    }
   ],
   "source": [
    "ivgd = IVGD()\n",
    "\n",
    "# train diffusion model\n",
    "print(\"ivgd.train_diffusion:\")\n",
    "print(\"========================\")\n",
    "diffusion_model = ivgd.train_diffusion(adj, train_dataset)\n",
    "print(\"========================\\n\")\n",
    "# train IVGD\n",
    "print(\"ivgd.train:\")\n",
    "print(\"========================\")\n",
    "ivgd_model, thres, auc, f1, pred = ivgd.train(\n",
    "    adj, train_dataset, diffusion_model)\n",
    "print(\"========================\\n\")\n",
    "print(\"training done\\n\")\n",
    "print(f\"train auc: {auc:.3f}, train f1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff4b9b6",
   "metadata": {},
   "source": [
    "### visualization\n",
    "visualize the predicted sources and the labeled sources and save the figure to the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4a3b830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /nfs/users/junxiang/personal/GraphSL/IVGD_source_prediction.png\n"
     ]
    }
   ],
   "source": [
    "pred = (pred >= thres)\n",
    "visualize_source_prediction(adj,pred[:,0],train_dataset[0][:,0].numpy(),save_dir=curr_dir,save_name=\"IVGD_source_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f490bc-3b2e-4cbb-98bb-d81ef9e0a641",
   "metadata": {},
   "source": [
    "#### testing\n",
    "\n",
    "test IVGD using the test set, and return the Metric object (accuracy, precision, recall, F1-Score and area under the ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27299a43-d5b6-44b4-8f63-47d600626e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test acc: 0.953, test pr: 0.867, test re: 0.867, test f1: 0.867, test auc: 0.986\n"
     ]
    }
   ],
   "source": [
    "metric = ivgd.test(adj, test_dataset, diffusion_model, ivgd_model, thres)\n",
    "print(f\"test acc: {metric.acc:.3f}, test pr: {metric.pr:.3f}, test re: {metric.re:.3f}, test f1: {metric.f1:.3f}, test auc: {metric.auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b02215f-8c3b-4556-99fb-a93d6c6de55d",
   "metadata": {},
   "source": [
    "### SLVAE\n",
    "\n",
    "#### training\n",
    "\n",
    "train SLVAE using the training set, and return the SLVAE model, the latent representations of training seed vector from VAE, the optimal threshold, the area under the ROC curve, the F1-score, and source predictions\n",
    "source predictions can be utilized to adjust the parameter `thres_list` in `slvae.train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f737ea7-ad9e-4834-a624-069c7333ccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ivgd.train:\n",
      "========================\n",
      "train SLVAE:\n",
      "Epoch [0/100], loss = 0.621\n",
      "Epoch [10/100], loss = 0.148\n",
      "Epoch [20/100], loss = 0.233\n",
      "Epoch [30/100], loss = 0.064\n",
      "Epoch [40/100], loss = 0.061\n",
      "Epoch [50/100], loss = 0.057\n",
      "Epoch [60/100], loss = 0.303\n",
      "Epoch [70/100], loss = 0.046\n",
      "Epoch [80/100], loss = 0.043\n",
      "Epoch [90/100], loss = 0.348\n",
      "infer seed from training set:\n",
      "Epoch [0/10], obj = -4.4079\n",
      "thres = 0.088, train_f1 = 0.923\n",
      "thres = 0.177, train_f1 = 0.923\n",
      "thres = 0.265, train_f1 = 0.923\n",
      "thres = 0.354, train_f1 = 0.921\n",
      "thres = 0.442, train_f1 = 0.920\n",
      "thres = 0.531, train_f1 = 0.906\n",
      "thres = 0.619, train_f1 = 0.877\n",
      "thres = 0.708, train_f1 = 0.849\n",
      "thres = 0.796, train_f1 = 0.757\n",
      "thres = 0.885, train_f1 = 0.561\n",
      "========================\n",
      "\n",
      "training done\n",
      "\n",
      "train auc: 0.985, train f1: 0.923\n"
     ]
    }
   ],
   "source": [
    "slave = SLVAE()\n",
    "\n",
    "print(\"ivgd.train:\")\n",
    "print(\"========================\")\n",
    "slvae_model, seed_vae_train, thres, auc, f1, pred = slave.train(\n",
    "    adj, train_dataset)\n",
    "print(\"========================\\n\")\n",
    "print(\"training done\\n\")\n",
    "print(f\"train auc: {auc:.3f}, train f1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67021c6",
   "metadata": {},
   "source": [
    "### visualization\n",
    "visualize the predicted sources and the labeled sources and save the figure to the current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "640fe30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figure saved to /nfs/users/junxiang/personal/GraphSL/SLVAE_source_prediction.png\n"
     ]
    }
   ],
   "source": [
    "pred = (pred >= thres)\n",
    "visualize_source_prediction(adj,pred[:,0],train_dataset[0][:,0].numpy(),save_dir=curr_dir,save_name=\"SLVAE_source_prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b095c21-52ab-4164-832c-afb1375518ff",
   "metadata": {},
   "source": [
    "#### testing\n",
    "test SLVAE using the test set, and return the Metric object (accuracy, precision, recall, F1-Score, and area under the ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6b8b69c0-d83d-4e53-b172-8df95aebfb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infer seed from test set:\n",
      "Epoch [0/10], obj = -4.4174\n",
      "Epoch [1/10], obj = -4.3993\n",
      "Epoch [2/10], obj = -4.3987\n",
      "Epoch [3/10], obj = -4.4159\n",
      "Epoch [4/10], obj = -4.4316\n",
      "Epoch [5/10], obj = -4.4177\n",
      "Epoch [6/10], obj = -4.3993\n",
      "Epoch [7/10], obj = -4.3897\n",
      "Epoch [8/10], obj = -4.3990\n",
      "Epoch [9/10], obj = -4.3832\n",
      "test acc: 0.971, test pr: 0.857, test re: 1.000, test f1: 0.923, test auc: 0.983\n"
     ]
    }
   ],
   "source": [
    "metric = slave.infer(test_dataset, slvae_model, seed_vae_train, thres)\n",
    "print(f\"test acc: {metric.acc:.3f}, test pr: {metric.pr:.3f}, test re: {metric.re:.3f}, test f1: {metric.f1:.3f}, test auc: {metric.auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93ebd4d",
   "metadata": {},
   "source": [
    "The performance of three GNN-based methods (GCNSI, IVGD and SLVAE) is signifcantly better than that of three prescribed methods (LPSI, NetSleuth, and OJC). This may be because GNN-based methods can learn rules from graph toplogy and information diffusion automactically, while prescribed methods have predefined rules, which may be less flexible than GNN-based methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
